{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../Phase 3/Jobenn_preprocessed_NCF_data.csv\"\n",
    "df = pd.read_csv(DATA_PATH, encoding='utf-8')\n",
    "\n",
    "# df.head()\n",
    "import random\n",
    "random.seed(42)\n",
    "df = df.sample(10)\n",
    "print(df.dtypes) # I want to see the type of the features\n",
    "print(df['label'])\n",
    "print(df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully its the last\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FIXED XAI EXECUTION ===\n",
      "\n",
      "üîç DEBUG: Loading structured CSV and constructing input texts...\n",
      "‚úÖ Loaded shape: (20186, 26)\n",
      "üîé Columns: ['protocol', 'flag', 'family', 'address', 'usd', 'seed_address', 'btc', 'netflow_bytes', 'ip_address', 'clusters', 'threats', 'port', 'time', 'prediction', 'label', 'text', 'segment', 'embeddings', 'dataset', 'r', 'rw', 'rx', 'rwc', 'rwx', 'rwxc', 'category']\n",
      "\n",
      "==================================================\n",
      "PROCESSING: BERT\n",
      "==================================================\n",
      "üîß Loading model from ./Tuned Models/bert_finetuned\n",
      "‚úÖ Test prediction: tensor([[9.9974e-01, 2.6269e-04]])\n",
      "\n",
      "üîÑ SHAP Text Explanations for BERT...\n",
      "‚úÖ SHAP text saved: Final_xai_outputs/shap_text_sample_0_BERT.html\n",
      "‚ö†Ô∏è Per-sample bar failed (sample 0): string index out of range\n",
      "‚úÖ SHAP text saved: Final_xai_outputs/shap_text_sample_1_BERT.html\n",
      "‚ö†Ô∏è Per-sample bar failed (sample 1): string index out of range\n",
      "‚úÖ Aggregate token bar saved: Final_xai_outputs/shap_aggregate_tokens_BERT.png\n",
      "\n",
      "üîÑ LIME for BERT...\n",
      "\n",
      "üìã LIME Predictions for BERT - Sample 0:\n",
      "Text: TCP APS Razy 1DiCeTjB btc: 0.3747814163415594 netflow_bytes: 0.4138859443477027 EB...\n",
      "Prediction probabilities: Benign: 0.9997, Ransomware: 0.0003\n",
      "\n",
      "LIME Feature Importance:\n",
      "  TCP: -0.1280\n",
      "  APS: -0.0974\n",
      "  1DiCeTjB: -0.0808\n",
      "  4138859443477027: -0.0626\n",
      "  0: -0.0515\n",
      "\n",
      "LIME Explanation Table:\n",
      "Feature                       Weight         \n",
      "---------------------------------------------\n",
      "TCP                           -0.1280\n",
      "APS                           -0.0974\n",
      "1DiCeTjB                      -0.0808\n",
      "4138859443477027              -0.0626\n",
      "0                             -0.0515\n",
      "\n",
      "üìã LIME Predictions for BERT - Sample 1:\n",
      "Text: TCP R SamSam 1SYSTEMQ btc: 0.4400928335931486 netflow_bytes: 0.8871749579653909 EB...\n",
      "Prediction probabilities: Benign: 0.8638, Ransomware: 0.1362\n",
      "\n",
      "LIME Feature Importance:\n",
      "  TCP: -0.2974\n",
      "  SamSam: 0.2164\n",
      "  0: -0.2009\n",
      "  btc: 0.1771\n",
      "  4400928335931486: -0.1347\n",
      "\n",
      "LIME Explanation Table:\n",
      "Feature                       Weight         \n",
      "---------------------------------------------\n",
      "TCP                           -0.2974\n",
      "SamSam                        +0.2164\n",
      "0                             -0.2009\n",
      "btc                           +0.1771\n",
      "4400928335931486              -0.1347\n",
      "\n",
      "==================================================\n",
      "PROCESSING: RoBERTa\n",
      "==================================================\n",
      "üîß Loading model from ./Tuned Models/roberta_finetuned\n",
      "‚úÖ Test prediction: tensor([[9.9999e-01, 1.3259e-05]])\n",
      "\n",
      "üîÑ SHAP Text Explanations for RoBERTa...\n",
      "‚úÖ SHAP text saved: Final_xai_outputs/shap_text_sample_0_RoBERTa.html\n",
      "‚ö†Ô∏è Per-sample bar failed (sample 0): string index out of range\n",
      "‚úÖ SHAP text saved: Final_xai_outputs/shap_text_sample_1_RoBERTa.html\n",
      "‚ö†Ô∏è Per-sample bar failed (sample 1): string index out of range\n",
      "‚úÖ Aggregate token bar saved: Final_xai_outputs/shap_aggregate_tokens_RoBERTa.png\n",
      "\n",
      "üîÑ LIME for RoBERTa...\n",
      "\n",
      "üìã LIME Predictions for RoBERTa - Sample 0:\n",
      "Text: TCP APS Razy 1DiCeTjB btc: 0.3747814163415594 netflow_bytes: 0.4138859443477027 EB...\n",
      "Prediction probabilities: Benign: 1.0000, Ransomware: 0.0000\n",
      "\n",
      "LIME Feature Importance:\n",
      "  netflow_bytes: -0.0000\n",
      "  1DiCeTjB: -0.0000\n",
      "  btc: -0.0000\n",
      "  4138859443477027: 0.0000\n",
      "  TCP: -0.0000\n",
      "\n",
      "LIME Explanation Table:\n",
      "Feature                       Weight         \n",
      "---------------------------------------------\n",
      "netflow_bytes                 -0.0000\n",
      "1DiCeTjB                      -0.0000\n",
      "btc                           -0.0000\n",
      "4138859443477027              +0.0000\n",
      "TCP                           -0.0000\n",
      "\n",
      "üìã LIME Predictions for RoBERTa - Sample 1:\n",
      "Text: TCP R SamSam 1SYSTEMQ btc: 0.4400928335931486 netflow_bytes: 0.8871749579653909 EB...\n",
      "Prediction probabilities: Benign: 1.0000, Ransomware: 0.0000\n",
      "\n",
      "LIME Feature Importance:\n",
      "  netflow_bytes: -0.0000\n",
      "  btc: -0.0000\n",
      "  1SYSTEMQ: -0.0000\n",
      "  8871749579653909: 0.0000\n",
      "  4400928335931486: 0.0000\n",
      "\n",
      "LIME Explanation Table:\n",
      "Feature                       Weight         \n",
      "---------------------------------------------\n",
      "netflow_bytes                 -0.0000\n",
      "btc                           -0.0000\n",
      "1SYSTEMQ                      -0.0000\n",
      "8871749579653909              +0.0000\n",
      "4400928335931486              +0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Sibusiso Maduna \n",
    "## u21565687\n",
    "\n",
    "# ==============================\n",
    "# XAI WITH SHAP + LIME \n",
    "# ==============================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "# Config\n",
    "BERT_DIR = \"./Tuned Models/bert_finetuned\"\n",
    "ROBERTA_DIR = \"./Tuned Models/roberta_finetuned\"\n",
    "DATA_PATH = \"../Phase 3/Jobenn_preprocessed_NCF_data.csv\"\n",
    "\n",
    "OUTPUT_DIR = \"Final_xai_outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "SHAP_EXPLANATIONS = 2\n",
    "LIME_EXPLANATIONS = 2\n",
    "TEST_SAMPLES = 50\n",
    "\n",
    "# ==============================\n",
    "# FIXED DATA LOADING\n",
    "# ==============================\n",
    "\n",
    "def debug_load_data():\n",
    "    print(\"\\nüîç DEBUG: Loading structured CSV and constructing input texts...\")\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_PATH, encoding='utf-8')\n",
    "        print(f\"‚úÖ Loaded shape: {df.shape}\")\n",
    "        print(f\"üîé Columns: {df.columns.tolist()}\")\n",
    "\n",
    "        if df.isna().all().all():\n",
    "            raise ValueError(\"‚ùå All data is NaN - Check the CSV format.\")\n",
    "\n",
    "        candidate_columns = ['protocol', 'flag', 'family', 'address', 'btc', 'netflow_bytes', 'segment']\n",
    "        texts = []\n",
    "        for _, row in df.iterrows():\n",
    "            parts = []\n",
    "            for col in candidate_columns:\n",
    "                if col in df.columns and pd.notna(row[col]):\n",
    "                    val = row[col]\n",
    "                    parts.append(f\"{col}: {val}\" if isinstance(val, (int, float)) else str(val))\n",
    "            texts.append(\" \".join(parts) if parts else \"missing_text\")\n",
    "\n",
    "        if 'label' in df.columns:\n",
    "            label_col = 'label'\n",
    "        elif 'category' in df.columns:\n",
    "            label_col = 'category'\n",
    "        else:\n",
    "            raise ValueError(\"‚ùå No label or category column found.\")\n",
    "\n",
    "        labels = df[label_col].apply(lambda l: 1 if str(l).strip().lower() in ['1', 'ransomware', 'malicious'] else 0).tolist()\n",
    "\n",
    "        if len(texts) > TEST_SAMPLES:\n",
    "            texts = texts[:TEST_SAMPLES]\n",
    "            labels = labels[:TEST_SAMPLES]\n",
    "\n",
    "        return texts, labels\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Exception in data loading: {e}\")\n",
    "        exit()\n",
    "\n",
    "# ==============================\n",
    "# TEXT-BASED SHAP MULTIPLE SAMPLE PLOTS\n",
    "# ==============================\n",
    "\n",
    "def shap_text_multi_sample(model, tokenizer, device, texts, model_name):\n",
    "    print(f\"\\nüîÑ SHAP Text Explanations for {model_name}...\")\n",
    "\n",
    "    # --- Robust coercion: anything -> list[str] ---\n",
    "    def _to_text_list(x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = x.ravel().tolist()\n",
    "        elif isinstance(x, pd.Series):\n",
    "            x = x.tolist()\n",
    "        elif not isinstance(x, (list, tuple)):\n",
    "            x = [x]\n",
    "        out = []\n",
    "        for t in x:\n",
    "            if isinstance(t, str):\n",
    "                out.append(t)\n",
    "            elif isinstance(t, (list, tuple, np.ndarray)):\n",
    "                out.append(\" \".join(map(str, t)))\n",
    "            else:\n",
    "                out.append(str(t))\n",
    "        return out\n",
    "\n",
    "    # --- Batch predictor returning (batch, n_classes) ---\n",
    "    def predict_proba(texts_like):\n",
    "        texts_list = _to_text_list(texts_like)\n",
    "        enc = tokenizer(texts_list, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "        if device != -1:\n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "    masker = shap.maskers.Text(tokenizer)\n",
    "    explainer = shap.Explainer(predict_proba, masker, output_names=[\"Benign\", \"Ransomware\"])\n",
    "\n",
    "    k = min(SHAP_EXPLANATIONS, len(texts))\n",
    "    sample_texts = texts[:k]\n",
    "\n",
    "    # Compute explanations for multiple samples (Explanation of length k)\n",
    "    exps = explainer(sample_texts, silent=True)\n",
    "\n",
    "    # 1) Per-sample HTML + per-sample bar/waterfall (class 1)\n",
    "    for i in range(k):\n",
    "        e = exps[i]                     # single-sample Explanation\n",
    "        # slice to class 1 safely\n",
    "        e1 = e[..., 1] if getattr(e, \"values\", None) is not None and np.ndim(e.values) == 2 else e\n",
    "        # HTML text plot\n",
    "        try:\n",
    "            vis = shap.plots.text(e1, display=False)\n",
    "            out_html = f\"{OUTPUT_DIR}/shap_text_sample_{i}_{model_name}.html\"\n",
    "            with open(out_html, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(getattr(vis, \"data\", vis))\n",
    "            print(f\"‚úÖ SHAP text saved: {out_html}\")\n",
    "        except Exception as err:\n",
    "            print(f\"‚ö†Ô∏è Could not save SHAP text HTML for sample {i}: {err}\")\n",
    "\n",
    "        # Per-sample bar\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.plots.bar(e1, show=False, max_display=20)\n",
    "            plt.title(f\"{model_name} ‚Äì Sample {i} ‚Äì Ransomware\", fontsize=13)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{OUTPUT_DIR}/shap_bar_{model_name}_sample{i}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        except Exception as err:\n",
    "            print(f\"‚ö†Ô∏è Per-sample bar failed (sample {i}): {err}\")\n",
    "\n",
    "        # Optional waterfall\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.plots.waterfall(e1, show=False, max_display=20)\n",
    "            plt.title(f\"{model_name} ‚Äì Waterfall ‚Äì Sample {i}\", fontsize=13)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{OUTPUT_DIR}/shap_waterfall_{model_name}_sample{i}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "        except Exception as err:\n",
    "            print(f\"‚ö†Ô∏è Waterfall failed (sample {i}): {err}\")\n",
    "\n",
    "    # 2) Aggregate top tokens across samples (manual Matplotlib bar chart)\n",
    "    try:\n",
    "        from collections import defaultdict\n",
    "        token_scores = defaultdict(float)\n",
    "\n",
    "        for i in range(k):\n",
    "            e = exps[i]\n",
    "            vals = e.values\n",
    "            # get per-token contribs for class 1\n",
    "            per_token = vals[:, 1] if np.ndim(vals) == 2 else np.asarray(vals).ravel()\n",
    "            # tokens (text features)\n",
    "            toks = e.data\n",
    "            # e.data may be nested; coerce to a flat list of strings\n",
    "            if isinstance(toks, (list, tuple, np.ndarray)):\n",
    "                tokens_list = [str(t) for t in (toks.tolist() if isinstance(toks, np.ndarray) else toks)]\n",
    "            else:\n",
    "                tokens_list = [str(toks)]\n",
    "            # accumulate mean |shap|\n",
    "            for t, s in zip(tokens_list, per_token):\n",
    "                token = t.strip()\n",
    "                if token:  # skip empty\n",
    "                    token_scores[token] += float(abs(s))\n",
    "\n",
    "        # top-N tokens\n",
    "        topN = 25\n",
    "        top_items = sorted(token_scores.items(), key=lambda kv: kv[1], reverse=True)[:topN]\n",
    "        if top_items:\n",
    "            tokens, scores = zip(*top_items)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            y = np.arange(len(tokens))[::-1]\n",
    "            plt.barh(y, scores[::-1])\n",
    "            plt.yticks(y, [t for t in tokens[::-1]])\n",
    "            plt.xlabel(\"Aggregate |SHAP|\")\n",
    "            plt.title(f\"{model_name} ‚Äì Aggregate Top Tokens (Ransomware)\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{OUTPUT_DIR}/shap_aggregate_tokens_{model_name}.png\", dpi=150, bbox_inches=\"tight\")\n",
    "            plt.close()\n",
    "            print(f\"‚úÖ Aggregate token bar saved: {OUTPUT_DIR}/shap_aggregate_tokens_{model_name}.png\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No tokens collected for aggregate plot.\")\n",
    "    except Exception as err:\n",
    "        print(f\"‚ö†Ô∏è Aggregate token plot failed: {err}\")\n",
    "# ==============================\n",
    "# LIME RE-INTEGRATION (FIXED)\n",
    "# ==============================\n",
    "\n",
    "def simple_lime_analysis(model, tokenizer, device, texts, model_name):\n",
    "    print(f\"\\nüîÑ LIME for {model_name}...\")\n",
    "\n",
    "    def predict_proba(texts_list):\n",
    "        all_probs = []\n",
    "        for text in texts_list:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128, padding=True)\n",
    "            if device != -1:\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "        return np.array(all_probs)\n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=[\"Benign\", \"Ransomware\"])\n",
    "    success = 0\n",
    "\n",
    "    for i, text in enumerate(texts[:LIME_EXPLANATIONS]):\n",
    "        try:\n",
    "            exp = explainer.explain_instance(\n",
    "                text, predict_proba, num_features=5, num_samples=50\n",
    "            )\n",
    "            exp.save_to_file(f\"{OUTPUT_DIR}/lime_{model_name}_sample{i}.html\")\n",
    "            \n",
    "            # Create matplotlib figure\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            exp.as_pyplot_figure()\n",
    "            plt.title(f\"LIME - {model_name} - Sample {i}\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{OUTPUT_DIR}/lime_{model_name}_sample{i}.png\", dpi=120)\n",
    "            plt.close()\n",
    "            \n",
    "            # Show the predictions with table (FIXED VERSION)\n",
    "            print(f\"\\nüìã LIME Predictions for {model_name} - Sample {i}:\")\n",
    "            print(f\"Text: {text[:100]}...\")\n",
    "            \n",
    "            # Get prediction probabilities\n",
    "            probs = predict_proba([text])[0]\n",
    "            print(f\"Prediction probabilities: Benign: {probs[0]:.4f}, Ransomware: {probs[1]:.4f}\")\n",
    "            \n",
    "            # Show LIME explanation as text\n",
    "            print(\"\\nLIME Feature Importance:\")\n",
    "            for feature, weight in exp.as_list():\n",
    "                print(f\"  {feature}: {weight:.4f}\")\n",
    "            \n",
    "            # Create a simple text-based table\n",
    "            print(\"\\nLIME Explanation Table:\")\n",
    "            print(\"Feature\".ljust(30) + \"Weight\".ljust(15))\n",
    "            print(\"-\" * 45)\n",
    "            for feature, weight in exp.as_list():\n",
    "                print(f\"{feature[:29].ljust(30)}{weight:+.4f}\")\n",
    "            \n",
    "            success += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå LIME failed for sample {i}: {e}\")\n",
    "\n",
    "    return success\n",
    "\n",
    "# ==============================\n",
    "# MODEL LOADING\n",
    "# ==============================\n",
    "\n",
    "def load_model(model_dir):\n",
    "    print(f\"üîß Loading model from {model_dir}\")\n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"‚ùå Directory not found: {model_dir}\")\n",
    "        return None, None, None\n",
    "\n",
    "    try:\n",
    "        device = 0 if torch.cuda.is_available() else -1\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        model.eval()\n",
    "        if device != -1:\n",
    "            model = model.to(device)\n",
    "        return model, tokenizer, device\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Loading failed: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ==============================\n",
    "# MAIN EXECUTION\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n=== FIXED XAI EXECUTION ===\")\n",
    "    texts, labels = debug_load_data()\n",
    "\n",
    "    models = {\n",
    "        \"BERT\": BERT_DIR,\n",
    "        \"RoBERTa\": ROBERTA_DIR\n",
    "    }\n",
    "\n",
    "    for model_name, model_dir in models.items():\n",
    "        print(f\"\\n{'='*50}\\nPROCESSING: {model_name}\\n{'='*50}\")\n",
    "\n",
    "        model, tokenizer, device = load_model(model_dir)\n",
    "        if model is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            inputs = tokenizer(texts[0], return_tensors=\"pt\", truncation=True)\n",
    "            if device != -1:\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                print(f\"‚úÖ Test prediction: {torch.softmax(outputs.logits, dim=-1)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Test prediction failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        shap_text_multi_sample(model, tokenizer, device, texts, model_name)\n",
    "        simple_lime_analysis(model, tokenizer, device, texts, model_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../Phase 3/Jobenn_preprocessed_NCF_data.csv\")\n",
    "print(df.columns.tolist())\n",
    "df['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
